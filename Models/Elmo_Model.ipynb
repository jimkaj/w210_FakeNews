{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 9371607073326031485), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 15935754859020216855), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:1, XLA_GPU, 17179869184, 1265569899953759313), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3031668525000473917), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 208863232, 16896926859332849371), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:1, GPU, 11154794087, 4065665577044160829)]\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# tests to see if gpu is working\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    print(devices)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"module_apply_default/bilm/Reshape_1:0\", shape=(2, 6, 512), dtype=float32)\n",
      "Tensor(\"module_apply_default_1/concat:0\", shape=(2, ?, 1024), dtype=float32)\n",
      "Tensor(\"module_apply_default_2/concat_1:0\", shape=(2, ?, 1024), dtype=float32)\n",
      "Tensor(\"module_apply_default_3/aggregation/mul_3:0\", shape=(2, 6, 1024), dtype=float32)\n",
      "Tensor(\"module_apply_default_4/truediv:0\", shape=(2, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test tensorflow hub elmo module\n",
    "\n",
    "elmo = hub.Module(\"module/module_elmo2/\", trainable=True)\n",
    "sentence_input = [\"the cat is on the mat\", \"what are you doing in evening\"]\n",
    "\n",
    "word_embeddings = elmo(\n",
    "    inputs = sentence_input, \n",
    "    signature = \"default\",\n",
    "    as_dict = True)[\"word_emb\"]\n",
    "\n",
    "lstm1_embeddings = elmo(\n",
    "    inputs = sentence_input, \n",
    "    signature = \"default\",\n",
    "    as_dict = True)[\"lstm_outputs1\"]\n",
    "\n",
    "lstm2_embeddings = elmo(\n",
    "    inputs = sentence_input, \n",
    "    signature = \"default\",\n",
    "    as_dict = True)[\"lstm_outputs2\"]\n",
    "\n",
    "elmo_embeddings = elmo(\n",
    "    inputs = sentence_input, \n",
    "    signature = \"default\",\n",
    "    as_dict = True)[\"elmo\"]\n",
    "\n",
    "default_embeddings = elmo(\n",
    "    inputs = sentence_input, \n",
    "    signature = \"default\",\n",
    "    as_dict = True)[\"default\"]\n",
    "\n",
    "\n",
    "print(word_embeddings)\n",
    "print(lstm1_embeddings)\n",
    "print(lstm2_embeddings)\n",
    "print(elmo_embeddings)\n",
    "print(default_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>...</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>len_content</th>\n",
       "      <th>len_title</th>\n",
       "      <th>num_exclaim_title</th>\n",
       "      <th>num_sentences_content</th>\n",
       "      <th>sentences_content</th>\n",
       "      <th>num_paras</th>\n",
       "      <th>num_punc_content</th>\n",
       "      <th>percent_punc_content_per_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>coed.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>https://coed.com/2018/01/23/boston-celtics-vs-...</td>\n",
       "      <td>VIEW GALLERY\\n\\nThe Boston Celtics are traveli...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>694</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>['VIEW GALLERY\\n\\nThe Boston Celtics are trave...</td>\n",
       "      <td>37</td>\n",
       "      <td>149</td>\n",
       "      <td>21.469741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>176</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/prophecy/2018/01/the-...</td>\n",
       "      <td>The Truth About the Israel-Palestine Conflict\\...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2663</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>['The Truth About the Israel-Palestine Conflic...</td>\n",
       "      <td>165</td>\n",
       "      <td>565</td>\n",
       "      <td>21.216673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>345</td>\n",
       "      <td>408</td>\n",
       "      <td>betootaadvocate.com</td>\n",
       "      <td>satire</td>\n",
       "      <td>http://www.betootaadvocate.com/humans-of-betoo...</td>\n",
       "      <td>ERROL PARKER | Editor-at-large | Contact\\n\\n“H...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>['ERROL PARKER | Editor-at-large | Contact\\n\\n...</td>\n",
       "      <td>43</td>\n",
       "      <td>141</td>\n",
       "      <td>34.729064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>369</td>\n",
       "      <td>433</td>\n",
       "      <td>beehivebugle.com</td>\n",
       "      <td>satire</td>\n",
       "      <td>http://beehivebugle.com/2013/11/18/american-fo...</td>\n",
       "      <td>American Fork’s East 17th Ward’s excitement er...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>459</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>['American Fork’s East 17th Ward’s excitement ...</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>24.618736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>603</td>\n",
       "      <td>685</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/watercooler-topics/20...</td>\n",
       "      <td>Hobby Historian Claims to Have Discovered Forg...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>['Hobby Historian Claims to Have Discovered Fo...</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>36.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1   id               domain    type  \\\n",
       "0           2             2             114  138             coed.com    fake   \n",
       "1           3             3             150  176    beforeitsnews.com    fake   \n",
       "2           6             6             345  408  betootaadvocate.com  satire   \n",
       "3           7             7             369  433     beehivebugle.com  satire   \n",
       "4          12            12             603  685    beforeitsnews.com    fake   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://coed.com/2018/01/23/boston-celtics-vs-...   \n",
       "1  http://beforeitsnews.com/prophecy/2018/01/the-...   \n",
       "2  http://www.betootaadvocate.com/humans-of-betoo...   \n",
       "3  http://beehivebugle.com/2013/11/18/american-fo...   \n",
       "4  http://beforeitsnews.com/watercooler-topics/20...   \n",
       "\n",
       "                                             content  \\\n",
       "0  VIEW GALLERY\\n\\nThe Boston Celtics are traveli...   \n",
       "1  The Truth About the Israel-Palestine Conflict\\...   \n",
       "2  ERROL PARKER | Editor-at-large | Contact\\n\\n“H...   \n",
       "3  American Fork’s East 17th Ward’s excitement er...   \n",
       "4  Hobby Historian Claims to Have Discovered Forg...   \n",
       "\n",
       "                   scraped_at                 inserted_at  ... summary source  \\\n",
       "0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632  ...     NaN    NaN   \n",
       "1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632  ...     NaN    NaN   \n",
       "2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632  ...     NaN    NaN   \n",
       "3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632  ...     NaN    NaN   \n",
       "4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632  ...     NaN    NaN   \n",
       "\n",
       "  len_content  len_title num_exclaim_title num_sentences_content  \\\n",
       "0         694          7                 0                    31   \n",
       "1        2663          6                 0                   102   \n",
       "2         406         11                 0                    29   \n",
       "3         459         11                 0                    25   \n",
       "4         172         13                 0                     9   \n",
       "\n",
       "                                   sentences_content  num_paras  \\\n",
       "0  ['VIEW GALLERY\\n\\nThe Boston Celtics are trave...         37   \n",
       "1  ['The Truth About the Israel-Palestine Conflic...        165   \n",
       "2  ['ERROL PARKER | Editor-at-large | Contact\\n\\n...         43   \n",
       "3  ['American Fork’s East 17th Ward’s excitement ...         15   \n",
       "4  ['Hobby Historian Claims to Have Discovered Fo...         11   \n",
       "\n",
       "  num_punc_content  percent_punc_content_per_len  \n",
       "0              149                     21.469741  \n",
       "1              565                     21.216673  \n",
       "2              141                     34.729064  \n",
       "3              113                     24.618736  \n",
       "4               62                     36.046512  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full/subset of the FNC dataset\n",
    "\n",
    "data = pd.read_csv(\"FNC_Final.csv\", engine = \"python\",error_bad_lines=False)\n",
    "# data = pd.read_csv(\"FNC_Subset.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142395, 27)\n",
      "count       142395\n",
      "unique           5\n",
      "top       reliable\n",
      "freq         47753\n",
      "Name: type, dtype: object\n",
      "['fake' 'satire' 'reliable' 'political' 'bias']\n",
      "count       142395\n",
      "unique           5\n",
      "top       reliable\n",
      "freq         47753\n",
      "Name: type, dtype: object\n",
      "['fake' 'satire' 'reliable' 'political' 'bias']\n"
     ]
    }
   ],
   "source": [
    "# examine summary stats for 'type' column\n",
    "\n",
    "print(data.shape)\n",
    "print(data['type'].describe())\n",
    "print(data['type'].unique())\n",
    "\n",
    "data['type'].fillna('unknown',inplace = True)\n",
    "print(data['type'].describe())\n",
    "print(data['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>...</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>len_content</th>\n",
       "      <th>len_title</th>\n",
       "      <th>num_exclaim_title</th>\n",
       "      <th>num_sentences_content</th>\n",
       "      <th>sentences_content</th>\n",
       "      <th>num_paras</th>\n",
       "      <th>num_punc_content</th>\n",
       "      <th>percent_punc_content_per_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, Unnamed: 0.1.1, id, domain, type, url, content, scraped_at, inserted_at, updated_at, title, authors, keywords, meta_keywords, meta_description, tags, summary, source, len_content, len_title, num_exclaim_title, num_sentences_content, sentences_content, num_paras, num_punc_content, percent_punc_content_per_len]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove articles from survey\n",
    "\n",
    "survey_articles= pd.read_csv('survey_articles.csv')\n",
    "survey_list= list(survey_articles['id'])\n",
    "to_delete= list(data[data.id.isin(survey_list)].index)\n",
    "data[data.id.isin(survey_list)]\n",
    "\n",
    "# Remove articles from survey\n",
    "data=data.drop(to_delete,axis=0)\n",
    "data[data.id.isin(survey_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "47753\n",
      "<class 'pandas.core.series.Series'>\n",
      "22280\n",
      "2863\n",
      "41166\n",
      "28332\n"
     ]
    }
   ],
   "source": [
    "# examine reliable, satire, fake, etc. articles\n",
    "\n",
    "reliable = data.loc[data['type'] == 'reliable']\n",
    "satire = data.loc[data['type'] == 'satire']\n",
    "fake = data.loc[data['type'] == 'fake']\n",
    "political = data.loc[data['type'] == 'political']\n",
    "bias = data.loc[data['type'] == 'bias']\n",
    "\n",
    "print(type(reliable['type']))\n",
    "print(len(reliable['type']))\n",
    "print(type(fake['type']))\n",
    "print(len(fake['type']))\n",
    "\n",
    "print(len(satire['type']))\n",
    "print(len(political['type']))\n",
    "print(len(bias['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>...</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>len_content</th>\n",
       "      <th>len_title</th>\n",
       "      <th>num_exclaim_title</th>\n",
       "      <th>num_sentences_content</th>\n",
       "      <th>sentences_content</th>\n",
       "      <th>num_paras</th>\n",
       "      <th>num_punc_content</th>\n",
       "      <th>percent_punc_content_per_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206654</td>\n",
       "      <td>206654</td>\n",
       "      <td>2547</td>\n",
       "      <td>9651885</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://www.nytimes.com/2014/07/16/realestate/...</td>\n",
       "      <td>Q. So you do what specifically?\\n\\nA. We revie...</td>\n",
       "      <td>2018-02-11 00:47:37.281256</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>548</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>['Q.', 'So you do what specifically?', 'A.', '...</td>\n",
       "      <td>55</td>\n",
       "      <td>174</td>\n",
       "      <td>31.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11786</td>\n",
       "      <td>11786</td>\n",
       "      <td>1691</td>\n",
       "      <td>535837</td>\n",
       "      <td>dailykos.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.dailykos.com/stories/2006/10/9/255...</td>\n",
       "      <td>Here's what Matt was reacting to:\\n\\nAfter 1 a...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>419</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>[\"Here's what Matt was reacting to:\\n\\nAfter 1...</td>\n",
       "      <td>45</td>\n",
       "      <td>203</td>\n",
       "      <td>48.448687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77182</td>\n",
       "      <td>77182</td>\n",
       "      <td>7190</td>\n",
       "      <td>3615091</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/opinion/2014/01/a-chi...</td>\n",
       "      <td>(Before It's News)\\n\\nThehas published a fasci...</td>\n",
       "      <td>2017-11-21T12:56:35.440396</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>572</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>[\"(Before It's News)\\n\\nThehas published a fas...</td>\n",
       "      <td>35</td>\n",
       "      <td>148</td>\n",
       "      <td>25.874126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50513</td>\n",
       "      <td>50513</td>\n",
       "      <td>2934</td>\n",
       "      <td>2335268</td>\n",
       "      <td>dailykos.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.dailykos.com/stories/2016/11/18/16...</td>\n",
       "      <td>A few days back I posted this diary, which rec...</td>\n",
       "      <td>2017-11-10T11:18:44.524042</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>872</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>['A few days back I posted this diary, which r...</td>\n",
       "      <td>61</td>\n",
       "      <td>349</td>\n",
       "      <td>40.022936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117659</td>\n",
       "      <td>117659</td>\n",
       "      <td>7792</td>\n",
       "      <td>5498904</td>\n",
       "      <td>rawstory.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.rawstory.com/2013/04/top-french-ga...</td>\n",
       "      <td>One of France’s most dangerous gangsters, know...</td>\n",
       "      <td>2017-11-27T01:15:02.476695</td>\n",
       "      <td>2018-02-08 19:18:34.468038</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>['One of France’s most dangerous gangsters, kn...</td>\n",
       "      <td>39</td>\n",
       "      <td>119</td>\n",
       "      <td>24.791667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1       id             domain  \\\n",
       "0      206654        206654            2547  9651885        nytimes.com   \n",
       "1       11786         11786            1691   535837       dailykos.com   \n",
       "2       77182         77182            7190  3615091  beforeitsnews.com   \n",
       "3       50513         50513            2934  2335268       dailykos.com   \n",
       "4      117659        117659            7792  5498904       rawstory.com   \n",
       "\n",
       "        type                                                url  \\\n",
       "0   reliable  https://www.nytimes.com/2014/07/16/realestate/...   \n",
       "1  political  https://www.dailykos.com/stories/2006/10/9/255...   \n",
       "2       fake  http://beforeitsnews.com/opinion/2014/01/a-chi...   \n",
       "3  political  https://www.dailykos.com/stories/2016/11/18/16...   \n",
       "4  political  https://www.rawstory.com/2013/04/top-french-ga...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Q. So you do what specifically?\\n\\nA. We revie...   \n",
       "1  Here's what Matt was reacting to:\\n\\nAfter 1 a...   \n",
       "2  (Before It's News)\\n\\nThehas published a fasci...   \n",
       "3  A few days back I posted this diary, which rec...   \n",
       "4  One of France’s most dangerous gangsters, know...   \n",
       "\n",
       "                   scraped_at                 inserted_at  ... summary  \\\n",
       "0  2018-02-11 00:47:37.281256  2018-02-11 00:14:20.346838  ...     NaN   \n",
       "1  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632  ...     NaN   \n",
       "2  2017-11-21T12:56:35.440396  2018-02-07 23:39:33.852671  ...     NaN   \n",
       "3  2017-11-10T11:18:44.524042  2018-02-07 23:39:33.852671  ...     NaN   \n",
       "4  2017-11-27T01:15:02.476695  2018-02-08 19:18:34.468038  ...     NaN   \n",
       "\n",
       "    source len_content  len_title num_exclaim_title num_sentences_content  \\\n",
       "0  nytimes         548          3                 0                    70   \n",
       "1      NaN         419          7                 0                    34   \n",
       "2      NaN         572          6                 0                    25   \n",
       "3      NaN         872          6                 0                    59   \n",
       "4      NaN         480          7                 0                    24   \n",
       "\n",
       "                                   sentences_content  num_paras  \\\n",
       "0  ['Q.', 'So you do what specifically?', 'A.', '...         55   \n",
       "1  [\"Here's what Matt was reacting to:\\n\\nAfter 1...         45   \n",
       "2  [\"(Before It's News)\\n\\nThehas published a fas...         35   \n",
       "3  ['A few days back I posted this diary, which r...         61   \n",
       "4  ['One of France’s most dangerous gangsters, kn...         39   \n",
       "\n",
       "  num_punc_content  percent_punc_content_per_len  \n",
       "0              174                     31.751825  \n",
       "1              203                     48.448687  \n",
       "2              148                     25.874126  \n",
       "3              349                     40.022936  \n",
       "4              119                     24.791667  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select random sample from reliable, fake, etc, then combine in a new dataframe\n",
    "\n",
    "fake = fake.sample(n=10000)\n",
    "reliable = reliable.sample(n=10000)\n",
    "satire = satire.sample (n=2863)\n",
    "political = political.sample(n=10000)\n",
    "bias = bias.sample(n=10000)\n",
    "# print(type(fake))\n",
    "# print(fake.head())\n",
    "\n",
    "data = reliable.append(fake)\n",
    "data = data.append(satire)\n",
    "data = data.append(political)\n",
    "data = data.append(bias)\n",
    "\n",
    "# shuffle the new dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe147d3f3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change \"reliable\", \"satire\", \"fake\", etc. to 0,1,2,etc.\n",
    "\n",
    "data.loc[data['type'] == 'reliable', 'type'] = 0.0\n",
    "data.loc[data['type'] == 'political', 'type'] = 1.0\n",
    "data.loc[data['type'] == 'bias', 'type'] = 2.0\n",
    "data.loc[data['type'] == 'satire', 'type'] = 3.0\n",
    "data.loc[data['type'] == 'fake', 'type'] = 4.0\n",
    "data['content'] = data['title']+'\\n'+data['content']\n",
    "\n",
    "# plot the distribution,\n",
    "data['type'].plot.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30070\n",
      "8920\n",
      "3873\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test\n",
    "\n",
    "msk = np.random.rand(len(data)) < 0.7\n",
    "\n",
    "train = data[msk]\n",
    "validation = data[~msk]\n",
    "\n",
    "msk2 = np.random.rand(len(validation)) < 0.7\n",
    "\n",
    "val = validation[msk2]\n",
    "test = validation[~msk2]\n",
    "\n",
    "train_data = train[['content','type']].copy()\n",
    "val_data = val[['content','type']].copy()\n",
    "test_data = test[['content','type']].copy()\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe2a00c6550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of train_data\n",
    "train_data['type'].plot.hist()\n",
    "\n",
    "# plot the distribution of val_data\n",
    "val_data['type'].plot.hist()\n",
    "\n",
    "# plot the distribution of test_data\n",
    "test_data['type'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    #remove EOL \n",
    "    text = str(text).strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text= text.split(\" \")\n",
    "    \n",
    "    #remove stop words \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    arr= np.array(text)\n",
    "    # preprocess data to standardize lengths\n",
    "    #text= text[0:999]\n",
    "        \n",
    "    #text=' '.join(text)\n",
    "    \n",
    "#     text = replace_contraction(text)\n",
    "#     text = replace_links(text, \"link\")\n",
    "#     text = remove_numbers(text)\n",
    "#     text = re.sub(r'[,!@#$%^&*)(|/><\";:.?\\'\\\\}{]',\"\",text)\n",
    "#     text = text.lower()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Robert' 'W.' 'Barone' 'Q.' 'So' 'specifically?' '' 'A.' 'We' 'review'\n",
      " 'drawings,' 'contracts,' 'budgets,' 'well' 'permits' 'schedules,'\n",
      " 'determine' 'based' 'upon' 'completion' 'quality' 'documents' 'risks'\n",
      " 'related' 'client' 'going' 'forward.' '' 'Q.' 'What' 'environmental'\n",
      " 'issues' 'might' 'encounter?' '' 'A.' 'Our' 'firm' 'conducting' 'Phase'\n",
      " 'I' 'assessments' 'since' 'late' '’80s.' 'There' 'generally' 'many'\n",
      " 'surprises.' 'Some' 'biggest' 'problems' 'land' 'development' 'dry'\n",
      " 'cleaners,' 'gas' 'stations,' 'ways' 'handle' 'that.' '' 'Q.' 'Are'\n",
      " 'ever' 'instances' 'concluded' 'something' 'good' 'deal?' '' 'A.' 'Yes.'\n",
      " 'I' 'wouldn’t' 'say' 'many,' 'instances,' 'usually' 'ways' 'solve' 'it.'\n",
      " 'It’s' 'creative.' '' 'Q.' 'How' 'so?' '' 'A.' 'One' 'biggest' 'problems'\n",
      " 'right' 'speed' 'developers' 'trying' 'move' 'forward' 'with.' 'And'\n",
      " 'speed' 'incompleteness' 'documents' 'comes' 'higher' 'risk.' 'We' 'take'\n",
      " 'look' 'completion' 'documents,' 'may' 'suggest' 'little' 'money' 'set'\n",
      " 'aside' 'problems.' 'They' 'may' 'aggressive' 'schedule,' 'may' 'suggest'\n",
      " 'longer' 'schedule.' '' 'Photo' '' 'Q.' 'Who' 'clients?' '' 'A.' 'We'\n",
      " 'working' 'best' 'projects' 'New' 'York' 'City.' 'Some' 'would'\n",
      " 'Extell’s' 'One57.' 'I’m' 'still' 'working' 'that;' 'we’re'\n",
      " 'representing' 'lenders.' '' 'Our' 'involvement' 'usually' 'begins'\n",
      " 'start' 'construction,' 'follow' 'generally' 'end.' '' 'We’re' 'also'\n",
      " 'working' 'Forest' 'City' 'Ratner’s' 'B2' 'tower' 'Atlantic' 'Yards;'\n",
      " 'Related’s' 'platform' 'Hudson' 'Yards;' 'Silverstein’s' '30' 'Park'\n",
      " 'Place.' 'In' 'particular' 'instances' 'we’re' 'representing' 'lenders.'\n",
      " '' 'Newsletter' 'Sign' 'Up' 'Continue' 'reading' 'main' 'story' 'Please'\n",
      " 'verify' 'robot' 'clicking' 'box.' 'Invalid' 'email' 'address.' 'Please'\n",
      " 're-enter.' 'You' 'must' 'select' 'newsletter' 'subscribe' 'to.' 'Sign'\n",
      " 'Up' 'You' 'agree' 'receive' 'occasional' 'updates' 'special' 'offers'\n",
      " 'The' 'New' 'York' \"Times's\" 'products' 'services.' 'Thank'\n",
      " 'subscribing.' 'An' 'error' 'occurred.' 'Please' 'try' 'later.' 'View'\n",
      " 'New' 'York' 'Times' 'newsletters.' '' 'Remember,' 'lenders' 'taking'\n",
      " 'significant' 'risk.' 'Many' 'times' 'they’re' 'lending' '75' 'percent'\n",
      " 'money' 'related' 'project.' '' 'Q.' 'Which' 'lenders' 'working' 'with?'\n",
      " '' 'A.' 'All' 'big' 'names.' '' 'Q.' 'How' 'many' 'projects' 'working'\n",
      " 'right' 'now?' '' 'Advertisement' 'Continue' 'reading' 'main' 'story' ''\n",
      " 'A.' 'We' 'currently' 'working' 'approximately' '400' 'construction'\n",
      " 'projects' 'United' 'States,' 'since' 'January' '2013' 'we’ve' 'assigned'\n",
      " '175' 'projects' 'New' 'York' 'City,' 'worth' '$11' 'billion.' '' 'Of'\n",
      " '175' 'projects,' '70' 'percent' 'residential' '15' 'percent'\n",
      " 'hospitality.' 'We’re' 'also' 'office' 'retail.' '' 'Q.' 'Sounds' 'like'\n",
      " 'business' 'pretty' 'good.' '' 'A.' 'Business' 'great:' '2012' '2013'\n",
      " 'year' 'date,' '25,' '30' 'percent' 'growth' 'year.' '' 'We’re' 'busy'\n",
      " 'we’re' 'hiring.' 'I' 'believe' 'we’ve' 'hired' '40' 'people' 'far'\n",
      " 'year.' 'We’re' '185' 'people' 'firm.' 'Three' 'years' 'ago' 'probably'\n",
      " '90.' '' 'Q.' 'Where' 'would' 'like' 'see' 'company' 'road?' '' 'A.'\n",
      " 'We’re' 'strong' 'Northeast,' 'we’re' 'looking' 'expand' 'business'\n",
      " 'beyond' 'that.' 'We’re' 'branching' 'West' 'more.' '' 'Q.' 'Do' 'invest'\n",
      " 'real' 'estate?' '' 'A.' 'No,' 'no;' 'busy.' 'I' 'guess' 'I' 'know'\n",
      " 'many' 'things' 'go' 'wrong.']\n",
      "[0 1 4 ... 1 2 0]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# remove EOL, stopwords\n",
    "\n",
    "x_train = np.array(train_data[\"content\"].apply(cleanText))\n",
    "y_train = np.array(train_data[\"type\"])\n",
    "\n",
    "x_val = np.array(val_data[\"content\"].apply(cleanText))\n",
    "y_val = np.array(val_data[\"type\"])\n",
    "\n",
    "x_test = np.array(test_data[\"content\"].apply(cleanText))\n",
    "y_test = np.array(test_data[\"type\"])\n",
    "    \n",
    "print(x_train[0])\n",
    "print(y_train)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "30070\n",
      "['McCurry' 'Passed' 'Kerry' 'Campaign' 'Info' 'Bush' \"Here's\" 'Matt'\n",
      " 'reacting' 'to:' '' 'After' '1' 'a.m.,' 'Card' 'called' 'Cahill.' ''\n",
      " 'Cahill' 'said' 'Kerry' 'campaign' 'felt' 'confident.' '' 'Card' 'caught'\n",
      " 'guard.' '...' '--Is' 'going' 'phone' 'call?\"' '' '\"We' 'calling' 'you,\"'\n",
      " 'Cahill' 'replied.' 'She' 'seemed' 'half' 'asking' 'whether' 'Bush'\n",
      " 'would' 'calling' 'Kerry' 'concede.' '' '(snip)' '' 'Matalin' 'married'\n",
      " 'James' 'Carville,' 'Democrat' 'chief' 'political' 'strategist' 'Bill'\n",
      " 'Clinton' '1992.' '...' '...' '' '\"Look,' 'I' 'know' 'hard' 'you,\"'\n",
      " 'told' 'sympathetically.' '' 'Carville' 'told' 'inside' 'news.' 'The'\n",
      " 'Kerry' 'campaign' 'going' 'challenge' 'provisional' 'ballots'\n",
      " 'Ohio--perhaps' '250,000' 'them.' '\"I' 'agree' 'it,\"' 'Carville' 'said.'\n",
      " '\"I\\'m' 'telling' \"that's\" \"they're\" 'talking' 'about.\"' '' 'Matalin'\n",
      " 'went' 'report' 'Cheney.' '' 'What?' 'vice' 'president' 'asked.' '...' ''\n",
      " '\"You\\'d' 'better' 'tell' 'president,\"' 'Cheney' 'told' 'her.' '...' ''\n",
      " '\"They\\'re' 'going' 'contest' 'it,\"' 'Matalin' 'said.' '' '\"What']\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "x_train = pad_sequences(x_train, value= \"PAD\", dtype=object, padding= 'post', truncating = 'post', maxlen=128)\n",
    "x_val = pad_sequences(x_val, value= \"PAD\", dtype=object, padding= 'post', truncating = 'post', maxlen=128)\n",
    "x_test = pad_sequences(x_test, value= \"PAD\", dtype=object, padding= 'post', truncating = 'post', maxlen=128)\n",
    "\n",
    "print(len(x_train[1]))\n",
    "print(len(x_train))\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30070\n",
      "McCurry Passed Kerry Campaign Info Bush Here's Matt reacting to:  After 1 a.m., Card called Cahill.  Cahill said Kerry campaign felt confident.  Card caught guard....--Is going phone call?\"  \"We calling you,\" Cahill replied. She seemed half asking whether Bush would calling Kerry concede.  (snip)  Matalin married James Carville, Democrat chief political strategist Bill Clinton 1992.......  \"Look, I know hard you,\" told sympathetically.  Carville told inside news. The Kerry campaign going challenge provisional ballots Ohio--perhaps 250,000 them. \"I agree it,\" Carville said. \"I'm telling that's they're talking about.\"  Matalin went report Cheney.  What? vice president asked.... \"You'd better tell president,\" Cheney told her.... \"They're going contest it,\" Matalin said.  \"What\n"
     ]
    }
   ],
   "source": [
    "# convert list of tokens, to list of strings\n",
    "\n",
    "def tok_to_str(tokens):\n",
    "    text = []\n",
    "    for x in tokens:\n",
    "        text.append(TreebankWordDetokenizer().detokenize(x))\n",
    "    return text\n",
    "    \n",
    "x_train = tok_to_str(x_train)\n",
    "x_val = tok_to_str(x_val)\n",
    "x_test = tok_to_str(x_test)\n",
    "\n",
    "print(len(x_train))\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable = True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable, name=\"{}_module\".format(self.name))\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model\n",
    "def build_model(): \n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(5, activation='softmax')(dense)\n",
    "\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.train.AdamOptimizer(0.001), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 14:01:25.366288 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0805 14:01:25.367607 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 14:01:26.774758 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0805 14:01:26.807366 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 14:01:26.818593 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0805 14:01:26.964306 140614186043136 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "elmo_embedding_layer_1 (Elmo (None, 1024)              4         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 263,689\n",
      "Trainable params: 263,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 14:01:27.417452 140614186043136 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30070 samples, validate on 3873 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[node checkpoint_initializer_30 (defined at /usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py:399) ]]\n\nOriginal stack trace for 'checkpoint_initializer_30':\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-f1b8af25b514>\", line 3, in <module>\n    elmo = hub.Module(\"module/module_elmo2/\", trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/module.py\", line 169, in __init__\n    tags=self._tags)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 340, in _create_impl\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 391, in __init__\n    self._init_state(name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 399, in _init_state\n    self._variable_map)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1684, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1691, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[{{node checkpoint_initializer_30}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e9f27688b17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           batch_size=128)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[node checkpoint_initializer_30 (defined at /usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py:399) ]]\n\nOriginal stack trace for 'checkpoint_initializer_30':\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-f1b8af25b514>\", line 3, in <module>\n    elmo = hub.Module(\"module/module_elmo2/\", trainable=True)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/module.py\", line 169, in __init__\n    tags=self._tags)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 340, in _create_impl\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 391, in __init__\n    self._init_state(name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_hub/native_module.py\", line 399, in _init_state\n    self._variable_map)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1684, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1691, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Build and fit\n",
    "model = build_model()\n",
    "model.fit(np.array(x_train, dtype=object), \n",
    "          y_train,\n",
    "          validation_data=(np.array(x_test, dtype=object), y_test),\n",
    "          epochs=1,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = ElmoEmbeddingLayer()(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(5, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.train.AdamOptimizer(0.001), metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(np.array(x_train, dtype=object), \n",
    "          y_train,\n",
    "          validation_data=(np.array(x_val, dtype=object), y_val),\n",
    "          epochs=10,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the confusion matrix\n",
    "import scikitplot.plotters as skplt\n",
    "\n",
    "def plot_cmat(yte, ypred):\n",
    "    '''Plotting confusion matrix'''\n",
    "    skplt.plot_confusion_matrix(yte, ypred)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "y_pred = np.array(np.argmax(model.predict(np.array(x_test))))\n",
    "plot_cmat(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ElmoModel.h5')\n",
    "pre_save_preds = np.argmax(model.predict(np.array(np.array(x_test), dtype=object)[0:100])) # predictions before we clear and reload model\n",
    "\n",
    "# Clear and load model\n",
    "model = None\n",
    "model = build_model()\n",
    "model.load_weights('ElmoModel.h5')\n",
    "\n",
    "# post_save_preds = model.predict(np.array(x_test, dtype=object)[0:100]) # predictions after we clear and reload model\n",
    "# # all(pre_save_preds == post_save_preds) # Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
