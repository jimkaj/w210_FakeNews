{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training to Spot Fake News\n",
    "### Research Question\n",
    "Is training developed to innoculate people against fake news effective? We ran an experiment that tested two training methods designed to help people spot fake news.\n",
    "### Method\n",
    "Partipcants were randomly assigned to one of three conditions. Participants in the first condition played the [Bad News Game](https://getbadnews.com/#intro) designed to \"vaccinate the world against disinformation\". Participants assigned to the second condition watched a [video](https://www.factcheck.org/2016/12/video-spotting-fake-news/) \"How to Spot Fake News\" cretaed by [factcheck.org](https://www.factcheck.org/). A third condition served as a control condition.\n",
    "\n",
    "Participants were then asked to classify 20 articles into one of five categories: fake news, satire, extreme bias, political, or credible.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract, Transform, Load \n",
    "Take original Qualtircs csv file, remove rejected subjects, complete transformations, save clean data .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original Qualtrics .csv file.\n",
    "df_raw = pd.read_csv('data/Spot Fake News_July 28, 2019_13.40.csv', skiprows=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rejected responses from data\n",
    "df_raw = df_raw[df_raw.Consent != 0] # Take out surveys where participant did not consent\n",
    "df_raw = df_raw[df_raw.Finished != 0] # Take out incomplete surveys\n",
    "df_raw = df_raw[df_raw.mTurkID != 'asd'] # Non-sensical text responses/incorrect completion code\n",
    "df_raw = df_raw[df_raw.mTurkID != 'A1TXOZQU1O4F0N'] # Response not in mTurk\n",
    "df_raw = df_raw[df_raw.mTurkID != 'A5LYLHG880ABE'] # Worker repeated survey\n",
    "df_raw = df_raw[df_raw.mTurkID != 'AZM3H44W1D65P'] # Response not in mTurk\n",
    "df_raw = df_raw[df_raw.mTurkID != 'A1YC558J4E5KZ'] # Worker repeated survey\n",
    "df_raw = df_raw[df_raw.mTurkID != 'AK2C9AX5QJWUU'] # Incorrect completion code\n",
    "df_raw = df_raw[df_raw.mTurkID != 'A110KENBXU7SUJ'] # Incorrect completion code\n",
    "df_raw = df_raw[df_raw.mTurkID != 'AJ60KRY0FTB1F'] # Incorrect completion code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for cleaned data\n",
    "col_names = ['ID','Cond','Cor01','Cor02','Cor03','Cor04','Cor05','Cor06','Cor07','Cor08','Cor09',\\\n",
    "            'Cor10','Cor11','Cor12','Cor13','Cor14','Cor15','Cor16','Cor17','Cor18','Cor19','Cor20',\\\n",
    "            'TotCor']\n",
    "df_clean = pd.DataFrame(columns=col_names)\n",
    "df_clean.ID = df_raw.mTurkID\n",
    "df_clean.Cond = df_raw.Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variable Description\n",
    "ID: Subject ID (mTurk ID)\n",
    "\n",
    "Cond: Assigned experimental condition. T1=Training Game, T2=Training video, C=Control(no training)\n",
    "\n",
    "Cor01-Cor20: Correct categorization made for Article #. '1' if assigned correctly, '0' else. \n",
    "\n",
    "TotCor: Total correct out of 20 articles classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record if article coded correctly, Total number articles coded correctly\n",
    "df_clean.Cor01 = np.where(df_raw.Article01==2, 1, 0)\n",
    "df_clean.Cor02 = np.where(df_raw.Article02==2, 1, 0)\n",
    "df_clean.Cor03 = np.where(df_raw.Article03==2, 1, 0)\n",
    "df_clean.Cor04 = np.where(df_raw.Article04==2, 1, 0)\n",
    "df_clean.Cor05 = np.where(df_raw.Article05==2, 1, 0)\n",
    "df_clean.Cor06 = np.where(df_raw.Article06==2, 1, 0)\n",
    "df_clean.Cor07 = np.where(df_raw.Article07==2, 1, 0)\n",
    "df_clean.Cor08 = np.where(df_raw.Article08==2, 1, 0)\n",
    "df_clean.Cor09 = np.where(df_raw.Article09==1, 1, 0)\n",
    "df_clean.Cor10 = np.where(df_raw.Article10==1, 1, 0)\n",
    "df_clean.Cor11 = np.where(df_raw.Article11==1, 1, 0)\n",
    "df_clean.Cor12 = np.where(df_raw.Article12==3, 1, 0)\n",
    "df_clean.Cor13 = np.where(df_raw.Article13==3, 1, 0)\n",
    "df_clean.Cor14 = np.where(df_raw.Article14==3, 1, 0)\n",
    "df_clean.Cor15 = np.where(df_raw.Article15==4, 1, 0)\n",
    "df_clean.Cor16 = np.where(df_raw.Article16==4, 1, 0)\n",
    "df_clean.Cor17 = np.where(df_raw.Article17==4, 1, 0)\n",
    "df_clean.Cor18 = np.where(df_raw.Article18==5, 1, 0)\n",
    "df_clean.Cor19 = np.where(df_raw.Article19==5, 1, 0)\n",
    "df_clean.Cor20 = np.where(df_raw.Article20==5, 1, 0)\n",
    "df_clean.TotCor = df_clean.Cor01+df_clean.Cor02+df_clean.Cor03+df_clean.Cor04+df_clean.Cor05+\\\n",
    "    df_clean.Cor06+df_clean.Cor07+df_clean.Cor08+df_clean.Cor09+df_clean.Cor10+df_clean.Cor11+\\\n",
    "    df_clean.Cor12+df_clean.Cor13+df_clean.Cor14+df_clean.Cor15+df_clean.Cor16+df_clean.Cor17+\\\n",
    "    df_clean.Cor18+df_clean.Cor19+df_clean.Cor20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy rates\n",
      "Control:  Cor01     0.340426\n",
      "Cor02     0.180851\n",
      "Cor03     0.436170\n",
      "Cor04     0.297872\n",
      "Cor05     0.265957\n",
      "Cor06     0.617021\n",
      "Cor07     0.563830\n",
      "Cor08     0.574468\n",
      "Cor09     0.744681\n",
      "Cor10     0.585106\n",
      "Cor11     0.585106\n",
      "Cor12     0.287234\n",
      "Cor13     0.436170\n",
      "Cor14     0.308511\n",
      "Cor15     0.159574\n",
      "Cor16     0.276596\n",
      "Cor17     0.180851\n",
      "Cor18     0.553191\n",
      "Cor19     0.340426\n",
      "Cor20     0.372340\n",
      "TotCor    8.106383\n",
      "dtype: float64\n",
      "T1:  Cor01     0.391753\n",
      "Cor02     0.164948\n",
      "Cor03     0.536082\n",
      "Cor04     0.298969\n",
      "Cor05     0.134021\n",
      "Cor06     0.567010\n",
      "Cor07     0.412371\n",
      "Cor08     0.608247\n",
      "Cor09     0.701031\n",
      "Cor10     0.618557\n",
      "Cor11     0.556701\n",
      "Cor12     0.381443\n",
      "Cor13     0.381443\n",
      "Cor14     0.350515\n",
      "Cor15     0.082474\n",
      "Cor16     0.237113\n",
      "Cor17     0.216495\n",
      "Cor18     0.484536\n",
      "Cor19     0.278351\n",
      "Cor20     0.195876\n",
      "TotCor    7.597938\n",
      "dtype: float64\n",
      "T2:  Cor01     0.405941\n",
      "Cor02     0.247525\n",
      "Cor03     0.455446\n",
      "Cor04     0.336634\n",
      "Cor05     0.178218\n",
      "Cor06     0.594059\n",
      "Cor07     0.564356\n",
      "Cor08     0.603960\n",
      "Cor09     0.792079\n",
      "Cor10     0.732673\n",
      "Cor11     0.613861\n",
      "Cor12     0.386139\n",
      "Cor13     0.287129\n",
      "Cor14     0.247525\n",
      "Cor15     0.099010\n",
      "Cor16     0.198020\n",
      "Cor17     0.306931\n",
      "Cor18     0.475248\n",
      "Cor19     0.346535\n",
      "Cor20     0.217822\n",
      "TotCor    8.089109\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate means\n",
    "print('Mean Accuracy rates')\n",
    "\n",
    "Control_Check = df_clean['Cond'] =='C'\n",
    "Control_Res = df_clean[Control_Check]\n",
    "print('Control: ', Control_Res.mean())\n",
    "\n",
    "T1_Check = df_clean['Cond'] =='T1'\n",
    "T1_Res = df_clean[T1_Check] \n",
    "print('T1: ', T1_Res.mean())\n",
    "\n",
    "T2_Check = df_clean['Cond'] =='T2'\n",
    "T2_Res = df_clean[T2_Check] \n",
    "print('T2: ', T2_Res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
